\chapter{Imlementación JPEG}\label{ch:implementacion}

Se implementó un codificador JPEG, lanzado al dominio público en github bajo el
nombre de TinyJPEG \cite{tiny_jpeg}. La ubicación permanente de esta biblioteca
está en \begin{alltt}https://github.com/serge-rgb/TinyJPEG \end{alltt}

Encima de TinyJPEG, se desarrolló un proyecto que extiende TinyJPEG para
implementar el algoritmo evolutivo \cite{gp_encoder}, localizado en
\begin{alltt}https://github.com/serge-rgb/gp_encoder\end{alltt}

En este capítulo se describen los detalles de ambos proyectos.

\section {Términos}
Se van a usar los términos \emph{debugging} y \emph{profiling} por su ubiquidad
en la literatura. \emph{debugging} se traduce como depurar y se define como el
proceso de encontrar y arreglar defectos de código. \emph{profiling} es el
proceso de encontrar los puntos en los que un programa puede ser modificado
para mejorar el desempeño.

\emph{General Purpose GPU}, o \emph{GPGPU} es el
término usado para la práctica de usar programar GPUs directamente, a
diferencia de el uso original, en el cual el GPU era un acelerador cuya
interfaz era una biblioteca de gráficas como OpenGL o DirectX.

% ============================================================
\section{Tecnologías}
% ============================================================

La elección de lenguaje para TinyJPEG fue C, en particular C99 \cite{c99}.
TinyJPEG fue lanzado con el objetivo de ser una biblioteca reutilizable por
otras personas, y ha encontrado cierto grado de éxito. Un planetario en París
usa TinyJPEG para capturar vídeo de sus simulaciones.

C es un lenguaje ideal para escribir cosas como codificadores. El lenguaje
permite mantener el nivel bajo de abstracción que se necesita y las
herramientas de \emph{debugging} son mejores para C y C++ que para casi
cualquier otro lenguaje.

Se escogió OpenCL para la implementación de GPGPU. OpenCL es un estándar abierto
para GPGPU y está soportado por Intel, Nvidia y AMD. La máquina en la que se
implementó este trabajo tiene una tarjeta Nvidia. Nvidia tiene su propio
lenguaje para GPGPU, llamado CUDA, que tiene mejor soporte para debugging y
profiling que OpenCL para sus tarjetas de video. Sin embargo, las herramientas
siguen siendo primitivas comparadas con lo que se tiene en el CPU. En cualquier
caso, uno termina haciendo hipótesis, experimentos y medidas para optimizar la
solución, aún teniendo herramientas sofisticadas. Se escogió OpenCL porque los
méritos relativos de facilidad de desarrollo no le ganan al soporte
multi-plataforma y al valor de apoyar estándares abiertos.

% ============================================================
\section{Arquitectura}
% ============================================================

TinyJPEG es minimalista. Consiste de un archivo de alrededor 1000 líneas. Está
escrito en el estilo popularizado por Sean Barrett de escribir un solo archivo
\verb+.h+ con la siguiente estructura:

\label{alg:stb}
\begin{code}[language=C][h]
    // Principio del archivo
    #pragma once

    // Definición de la interfaz.
    tje_encode_to_file(...);

    #ifdef TJE_IMPLEMENTATION

    // La implementación completa va aquí.
\end{code}

De esta manera, uno puede incluir \verb+#include <tiny_jpeg.h>+ como cualquier
\emph{header} de C, pero en uno de los archivos del proyecto, se hace esto:

\label{alg:stb_impl}
\begin{code}[language=C][h]
    #define TJE_IMPLEMENTATION
    #include <tiny_jpeg.h>
\end{code}

para definir la implementación completa. El propósito de esta técnica es
facilitar la distribución de bibliotecas en un lenguaje que no cuenta con un
sistema de distribución digital de módulos,
o siquiera un sistema de módulos.

Se exponen dos funciones como interfaz pública:

\begin{code}[language=C][h]
tje_encode_to_file(...)
tje_encode_to_file_at_quality(...)
\end{code}

La primera comprime con la tabla unitaria y la segunda ofrece tres posibles
niveles de calidad, todos correspondientes únicamente al uso de tres tablas de
cuantificación. Ambas funciones son \emph{wrappers} sobre la función principal
interna, que funciona de la siguiente manera:

Se prepara una estructura estática para hacer compresión de Huffman y se
pre-procesa la tabla según el algoritmo \ref{alg:fast-dct}, descrito en la
siguiente sección. A esto le llamamos el \emph{paso inicial}.
Cuando terminamos el \emph{paso inicial}, determinamos el número de bloques que
van a ser procesados. JPEG debe funcionar con imágenes cuyos tamaños verticales
y horizontales no son múltiplos de 8. Para esto la especificación sólo nos pide
como codificador redondear al siguiente múltiplo de 8. Al decodificador le pide
ignorar los datos extra. Para evitar artefactos, como convención se repite en
el bloque el color del último píxel de la imagen para cada columna extra y para
cada renglón extra. Si $w$ es el ancho de la imagen y $h$ es el alto, entonces
el número de bloques es
$n = (w + (8 - w \mod 8)) * (h + (8 - h \mod 8))$

Cada bloque se separa en tres bloques \verb+Y+, \verb+U+ \verb+V+ que a los que
se les aplica la función \verb+encode_MCU()+.

La función \verb+encode_MCU()+ es llamada así por el acrónimo \emph{MCU},
\emph{Minimum Coded Unit}. JPEG puede especificar un factor para describir los
bloques \verb+U+ y \verb+V+ con menos resolución, por nuestra relativa falta de
sensibilidad a la crominancia contra la luminancia, pero TinyJPEG no utiliza
esto. Otra posibilidad es usar diferentes tablas de codificación para
lumninancia y crominancia. TinyJPEG sí utiliza esto, escogiendo tablas con
mayor compresión para los bloques de crominancia.

El flujo de la lógica es parecido a como se describe en Español. Un \verb+for loop+ para extraer los bloques, y cada bloque se pasa como parámetro a la
función \verb+encode_MCU+.

\subsection{DummyJPEG} \label{sub:dummy}

A primera vista, el algoritmo JPEG se ve ``embarazosamente paralelo". Una
motivación para este trabajo fue la observación de que el algoritmo trabaja
dividiendo la imágenes en cuadros de $8\times8$, y el hecho de que los GPUs
actuales trabajan con instrucciones vectoriales de 64 elementos.

Desafortunadamente, el algoritmo JPEG no es paralelo. Aplicar codificación
delta al coeficiente DC introduce una dependencia de datos entre cada bloque de
\verb+Y+, \verb+U+ y \verb+V+ respectivamente. Para cada componente, cualquier
bloque después del primero depende del anterior para poder computar la
diferencia entre su coeficiente DC  y el de su antecesor.

Sin embargo, aunque JPEG es inherentemente secuencial para cada componente,
está muy cerca de ser paralelo. Si el \emph{Joint Photographic Experts Group}
no hubiera decidido tratar de manera diferente a los coeficientes DC y AC, el
algoritmo sería completamente paralelo.

Queremos darle la vuelta al problema, y la manera en que lo hacemos es creando un "Dummy JPEG": Un algoritmo que es \emph{casi} JPEG, pero que no es correcto.

La implementación de DummyJPEG empieza como un clon directo de TinyJPEG. Lo
primero que hacemos es cambiar las función que escribe a disco por una función
que va contando el número de bits. De esta manera, al aplicar el algoritmo no
tenemos una imagen, pero tenemos un reporte del tamaño de la imagen que
hubiéramos generado.

También cambiamos el algoritmo para aplicar la Transformada Inversa de Coseno
justo después de aplicar la DCT al bloque, para poder compararlos y calcular el
error.

Entonces, si nuestro algoritmo original para cada bloque en TinyJPEG es:

\begin{code}
    x = aplicar_dct(bloque);
    codificar(x)
\end{code}

Nuestro algoritmo para cada bloque en DummyJPEG se convierte en esto:

\begin{code}
    x = aplicar_dct(bloque)
    reportar_tamaño(x)
    y = aplicar_idct(x)
    reportar_error(bloque, y)
\end{code}

En donde \verb+reportar_error+ es una suma de la diferencia absoluta entre cada pixel del bloque original y del bloque reconstruido.

La manera en que volvemos paralelo a DummyJPEG es simplemente no codificar al
coeficiente DC. Esto introduce un error en el tamaño reportado pero no afecta
al error reportado. El error que introducimos viene de que contamos los bits de
la representación de los 63 coeficientes AC, pero no contamos los bits del
coeficiente DC. En las imágenes de prueba que se usaron para este trabajo, el
tamaño reportado es menor que el tamaño real entre un 10\% y 20\%. El error es
proporcionalmente más alto para imágenes con más energía en el primer
coeficiente.

La pregunta que nos hacemos es: ¿El error en el reporte de tamaño es significativo?

Las presión que ponemos en la evolución es hacia imágenes que son
indistinguibles de la original. Como el valor de cuantificación del primer
coeficiente afecta de manera importante a la calidad de imagen comprimida, las
tablas de la población rápidamente convergen a tener el primer valor de
cuantificación igual a 1. Esto quiere decir que para casi cualquier conjunto de
tablas que vayamos a comparar, estamos introduciendo el mismo error en el
reporte de los tamaños de las imágenes resultantes. Por lo tanto, podemos
despreocuparnos por completo de no tomar en cuenta el primer coeficiente.

% Describir el deseo de hacer una implementación paralela en el CPU
Ya que tenemos un algoritmo que es \emph{casi JPEG}, pero paralelo, seguimos con la tarea de cambiar la arquitectura del programa para paralelizarlo en el CPU. La razón por la que implementamos el paralelismo en el CPU antes de hacerlo en el GPU es principalmente la velocidad de desarrollo. La manera en que implementamos la versión paralela en CPU se hace como \emph{plan con maña}, en el moldeamos el código para que el flujo de ejecución en el CPU sea muy similar a la manera en que trabaja el GPU, intentando llegar al punto de que la implementación en el GPU se reduzca a un \emph{copy paste}, y que el esfuerzo que se aplique a la implementación del GPU sea solamente un trabajo de optimización de bajo nivel.

Cambiar este párrafo a algo más legible:

    La arquitectura del flujo de lógica cambia. En lugar de llamar la
        función \verb+encode_MCU+ una vez por bloque, se llama \emph{una sóla
    vez} para todos los bloques, en el caso de un sólo \emph{thread}. Para
múltiples threads, se dividen los arreglos de bloques entre el número de
trabajadores, y se la función se llama una vez por cada CPU.

Explicar que estamos evoucionando una tabla:

    Sólo procesa los bloques de luminancia. El algoritmo evolutivo genera
        una tabla por imagen. Usar la lumninancia exclusivamente requiere un
    tercio del trabajo y resulta en un cambio negligible en el reporte del
error.

El cambio arquitectural de DummyJPEG no sólo facilita la paralelización en CPU,
sino que hace posible la implementación del algoritmo paralelo en el GPU \ref{sec:GPGPU}. DummyJPEG procesa $N$ bloques a la vez y escribe a un arreglo de $N$ resultados. Un resultado es una tupla $(B, E)$ donde $B$ es el número de bits que el bloque consume después de ser codificado (con un ligero error inducido al ignorar el coeficiente DC) y $E$ es la suma de las diferencias absolutas pixel-por-pixel entre el bloque original y el bloque descomprimido.

El algoritmo paralelo trabaja en un patrón \emph{map-reduce}. La función \emph{map} es el proceso paralelo que acabamos de describir, y el \emph{reduce} consiste de:

\begin{code}
    B_total = 0;
    E_total = 0;
    Para todo resultado (B, E):
       B_total += B;
       E_total += E;
    Terminar el algoritmo, regresando (B_total, E_total).
\end{code}

La tupla que regresa DummyJPEG son los parametros a la función de selección
\ref{eq:fitness}.

% ============================================================
\section{Algoritmo DCT}
% ============================================================

A partir de la ecuacion \ref{eq:dct} se puede derivar directamente un algoritmo
simple para la \emph{DCT}:

\label{alg:dct}
\begin{code}[language=C][h]
    float DCT[64];
    for (int v = 0; v < 8; ++v) {
        for (int u = 0; u < 8; ++u) {
            DCT[v*8 + u] = F(u, v);
            // F es la traducción directa de definición DCT
    }
\end{code}

\verb+tiny_jpeg+ contiene dos implementaciones de \emph{DCT}, la que se deriva
directamente de la ecuación \ref{eq:dct} y que se describe en \ref{alg:dct}
muestra arriba, y una más rápida, desarrollada por \cite{ahmed_dct}.

El algoritmo \ref{alg:dct} no es práctico para un codificador JPEG y mucho
menos para este proyecto, que pretende ejecutar el algoritmo JPEG
potencialmente miles de veces para una sola imagen. Existen métodos calcular la
DCT (y su inversa, la IDCT) rápidamente. La discusión presentada aquí sobre el
desarrollo de algoritmos rápidos DCT es análoga para la inversa, ya que las
ecuaciones son muy similares (\ref{eq:dct}, \ref{eq:idct}).

Los algoritmos rápidos para calcular la \emph{DCT} están basados en la
observación de que la ecuación \ref{eq:dct} es lineal, y por lo tanto el
cálculo \emph{DCT} se puede expresar como $F(X) = A^{T}XA$ Donde $X$ es un bloque de $8\times8$ y A es la matriz:

\begin{equation}
    \label{eq:dct-matrix}
    \begin{bmatrix}
        \frac{\sqrt{2}}{2} & \frac{\sqrt{2}}{2} & \frac{\sqrt{2}}{2} & \frac{\sqrt{2}}{2} & \frac{\sqrt{2}}{2} & \frac{\sqrt{2}}{2} & \frac{\sqrt{2}}{2} & \frac{\sqrt{2}}{2} \\
        cos\frac{\pi}{16} & cos\frac{3\pi}{16}& cos\frac{5\pi}{16}& cos\frac{7\pi}{16}& cos\frac{9\pi}{16}& cos\frac{11\pi}{16}& cos\frac{13\pi}{16}& cos\frac{15\pi}{16} \\
        cos\frac{2\pi}{16} & cos\frac{6\pi}{16}& cos\frac{10\pi}{16}& cos\frac{14\pi}{16}& cos\frac{18\pi}{16}& cos\frac{22\pi}{16}& cos\frac{26\pi}{16}& cos\frac{30\pi}{16} \\
        cos\frac{3\pi}{16} & cos\frac{9\pi}{16}& cos\frac{15\pi}{16}& cos\frac{21\pi}{16}& cos\frac{27\pi}{16}& cos\frac{33\pi}{16}& cos\frac{39\pi}{16}& cos\frac{45\pi}{16} \\
        cos\frac{4\pi}{16} & cos\frac{12\pi}{16}& cos\frac{20\pi}{16}& cos\frac{28\pi}{16}& cos\frac{36\pi}{16}& cos\frac{44\pi}{16}& cos\frac{52\pi}{16}& cos\frac{60\pi}{16} \\
        cos\frac{5\pi}{16} & cos\frac{15\pi}{16}& cos\frac{25\pi}{16}& cos\frac{35\pi}{16}& cos\frac{45\pi}{16}& cos\frac{55\pi}{16}& cos\frac{65\pi}{16}& cos\frac{75\pi}{16} \\
        cos\frac{6\pi}{16} & cos\frac{18\pi}{16}& cos\frac{30\pi}{16}& cos\frac{42\pi}{16}& cos\frac{54\pi}{16}& cos\frac{66\pi}{16}& cos\frac{78\pi}{16}& cos\frac{90\pi}{16} \\
        cos\frac{7\pi}{16} & cos\frac{21\pi}{16}& cos\frac{35\pi}{16}& cos\frac{49\pi}{16}& cos\frac{63\pi}{16}& cos\frac{77\pi}{16}& cos\frac{91\pi}{16}& cos\frac{105\pi}{16}
    \end{bmatrix}
\end{equation}

Esta matriz tiene alta redundancia gracias a la simetría del coseno y al factor $16$. Por ejemplo, el cuarto elemento del segundo renglón es $cos\frac{7\pi}{16} \approx 0.19509$ igual al siguiente elemento del renglón salvo al signo: $cos\frac{9\pi}{16} \approx -0.19509$, que es igual al último elemento de la matriz: $cos\frac{105\pi}{16} \approx -0.19509$. Siguiendo este proceso simplificamos la matríz:

\begin{equation}
    \label{eq:dct-matrix-simple}
    \sqrt{2}/2
    \begin{bmatrix}
        1 & 1 & 1 & 1 & 1 & 1 & 1 & 1  \\
        a & c & d & f & -f & -d & -c & -a \\
        b & e & -e & -b & -b & -e & e & b \\
        c & -f & -a & -d & d & a & f & -c \\
        1 & -1 & -1 & 1 & 1 & -1 & -1 & 1\\
        d & -a & f & c & -c & -f & a & -d \\
        e & -b & b & -e & -e & b & -b & e \\
        f & -d & c & -a & a & -c & d & -f
    \end{bmatrix}
\end{equation}

donde

\begin{eqnarray*}
    a = \frac{2}{\sqrt{2}}cos\frac{\pi}{16}\\
    b = \frac{2}{\sqrt{2}}cos\frac{\pi}{8}\\
    c = \frac{2}{\sqrt{2}}cos\frac{3\pi}{16}\\
    d = \frac{2}{\sqrt{2}}cos\frac{5\pi}{16}\\
    e = \frac{2}{\sqrt{2}}cos\frac{3\pi}{8}\\
    f = \frac{2}{\sqrt{2}}cos\frac{7\pi}{16}
\end{eqnarray*}

Entonces, una columna Y del bloque procesado por DCT se puede descomponer así:

\begin{equation}
    \label{eq:dct-row}
    \begin{bmatrix}
        Y(0) \\
        Y(2) \\
        Y(4) \\
        Y(6)
    \end{bmatrix}
    = \frac{\sqrt{2}}{2} \begin{bmatrix}
        1 & 1 & 1 & 1  \\
        b & e & -e & -b \\
        1 & -1 & -1 & 1  \\
        e & -b & b & e
        \end {bmatrix} \begin {bmatrix}
        X(0) + X(7) \\
        X(1) + X(6) \\
        X(2) + X(5) \\
        X(3) + X(4)
        \end {bmatrix}
\end{equation}

\begin{equation*}
    \begin{bmatrix}
        Y(0) \\
        Y(2) \\
        Y(4) \\
        Y(6)
    \end{bmatrix}
    = \frac{\sqrt{2}}{2} \begin{bmatrix}
        a & -c & d & -f  \\
        c & f & -a & d  \\
        d & a & f & -c  \\
        f & d & c & a
        \end {bmatrix} \begin {bmatrix}
        X(0) - X(7) \\
        X(6) - X(1) \\
        X(2) - X(5) \\
        X(4) - X(3)
        \end {bmatrix}
\end{equation*}

donde $X$ es un renglón del bloque.

Por lo tanto, si aplicamos la ecuación \ref{eq:dct-row}, avanzando columna por columna por el bloque original, obtenemos el bloque DCT.

El algoritmo resultante es lo suficientemente rápido para no aparecer como un cuello de botella significativo al momento de hacer optimización.

% ============================================================
\section{Manejo de memoria}
% ============================================================

TinyJPEG no efectúa alojamiento dinámico de memoria. Aloja suficiente memoria en el \emph{stack} para guardar las tablas de Huffman y por razones de eficiencia también mantiene un \emph{buffer} de 8KB, que se usa para minimizar llamadas a sistema.

Para el algoritmo paralelo, no es posible mantener esta propiedad. TinyJPEG procesa la imagen un bloque a la vez, mientras que DummyJPEG recibe $N$ bloques y escribe $N$ resultados en paralelo. Esto forza al sistema a alojar memoria para los bloques y para los arreglos donde se guardan los resultados.

Si OpenCL se utiliza, DummyJPEG aloja memoria en el GPU para los arreglos de entrada y de salida, así como para las tablas de Huffman. La latencia es el punto débil de las arquitecturas GPU. Por razones de eficiencia, los arreglos que se usan una vez por imagen son definidos una sola vez. Esto incluye los arreglos de los bloques, las tablas de Huffman. Los únicos datos que deben ser actualizados en cada llamada al \emph{kernel} son la tabla DCT y los arreglos de resultados.


% ============================================================
\section{Optimización}
% ============================================================

% ============================================================
\section{GPGPU} \label{sec:GPGPU}
% ============================================================
