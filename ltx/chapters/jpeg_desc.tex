%************************************************
\chapter{Descripción de compresión JPEG con pérdida}\label{ch:jpeg_desc}
%************************************************

\section{Historia y Descripciones Breves de los Fundamentos Matemáticos}

La Teoría de Codificación es una sub-rama de la Teoría de la Información que
marcó el inicio del estudio formal de la compresión de datos. La Teoría de la
Información, nacida en 1948 con la publicación del artículo de Claude E.
Shannon ``A Mathematical Theory of Communication'' \cite{shannon}, gira
alrededor de los conceptos de \emph{densidad de información}, \emph{entropía de
información} y \emph{redundancia de información}.

La Codificación de Entropía son métodos de compresión sin pérdida de
información que no toman en cuenta el contenido. Los dos métodos más populares
actualmente son los Códigos de Huffman y la Codificación Aritmética.

Dos años después de la publicación de Shannon, David Huffman inventó lo que hoy
conocemos como Codificación Huffman \cite{Huffman}. Los Códigos de Huffman son
códigos de prefijos que minimizan la longitud de los códigos individuales. Se
mantienen hasta hoy como la técnica más aprovechada en algoritmos de compresión
sin pérdida.

Después de Huffman, el método más popular para reducir redundancia es la
Codificación Aritmética. Es un método más sofisticado que consigue mejores
resultados. Entre $5\%$ y $10\%$ según el estándar JPEG \cite{JPEGSTD}. La
especificación de la compresión JPEG incluye la capacidad de utilizar
codificación aritmética, pero en la práctica no tiende a ser usada. En
particular, las implementaciones de código abierto no podían usar legalmente
Codificación Aritmética ya que es una técnica altamente patentada
\cite{jpeg_patents}.

En 1974, Nasir Ahmed publicó un artículo describiendo su Transformada de Coseno
Discreta \emph{(DCT)}, por sus siglas en Inglés. La DCT es un caso particular
de la transformada de Fourier, restringida a los números reales.

La compresión JPEG como casi todos la usamos se basa en códigos de Huffman y en
la Transformada de Coseno Discreta.

% ============================================================
\section{Tipos de compresión}
% ============================================================

La compresión de datos puede ser \emph{con pérdida} o \emph{sin pérdida}. Una
compresión sin pérdida es una función biyectiva. El dominio de la función es el
espacio de datos que estamos interesados en comprimir. Los formatos de
compresión sin péridida funcionan identificando información redundante y
removiendo la redundancia, dejando la información intacta. La compresión con
pérdida hace esto también, pero también identifica información ``inecesaria''.
Dependiendo de la agresividad de la compresión, la pérdida de información puede
ser desde imperceptible a inaceptable.

El formato JPEG soporta varios tipos de compresión.

\begin{list}{}{} \item \emph{Baseline}

El tipo \emph{baseline} es el más popular y es el tipo de compresión en el que
se enfoca este trabajo. Por brevedad, a menos de que se especifique lo
contario, cuando el resto de este documento hable de compresión JPEG, estará
hablando del tipo \emph{baseline}. La compresión está basada en la Transformada
de Coseno Discreta para filtrar información innecesaria, y para reducir
redundancia puede utilizar Árboles de Huffman o Codificación Aritmética.

\item \emph{Progresivo}

El tipo \emph{progresivo} es similar a \emph{baseline}, pero se le agregan
propiedades deseables. La imagen se comprime en múltiples pasos, cada uno con
mayor detalle. Con el método \emph{progresivo}, se puede desplegar la imágen
sin que se tenga la totalidad de los datos en memoria.

La utilidad de este método es poder dibujar la imágen mientras se está
descargando de Internet. Cuando se está en un entorno con ancho de banda
limitado, o cuando se descarga una imágen muy grande, es de valor para el
usuario poder ver versiones de la imágen progresivamente más detalladas
mientras se descarga.

\item \emph{Sin pérdida}

La compresión sin pérdida fue agregada a JPEG ``por que tenían que'' y no hubo
un análisis riguroso para su diseño \cite{JPEGSTD}. Aunque la compresión JPEG
sin pérdida no es mala, formatos como PNG son altamente más populares y
efectivos. Mucho software simplemente no soporta JPEG con compresión sin
pérdida.

\item \emph{Compresión Jerárquica}

El modo jerárquico codifica la imágen en varias versiones, cada una a
diferentes resoluciones. Se guarda en una estructura ``piramidal''. La primera
imágen está comprimida a resolución completa, y cada imágen sucesiva se guarda
a la mitad de la resolución de la anterior. Esta pirámide se guarda en memoria
de imágen más pequeña a imágen más grande.

Este método es útil cuando la resolución de la imagen es muy grande, y la
aplicación no necesita o no es capaz de utilizar la imagen en su tamaño
completo.

\end{list}

% ============================================================
\section{Descripción de la Compresión \emph{Baseline} de JPEG}
% ============================================================

El codificador implementado en este trabajo es el \emph{Baseline JPEG}, al que
también se le refiere como \emph{DCT-Based Coding}, traducido aquí como
\emph{Codificación DCT}. Para el resto del documento, a menos que sea
necesario, se usará el término \emph{JPEG} para referirse a lo mismo que
\emph{Baseline JPEG}.

La codificación DCT divide a la imágen en bloques de $8\times8$ píxeles. Cada
bloque de $8\times8$ pasa por una serie de transformaciones y salen
secuencialmente como datos comprimidos.

El primer paso en el \emph{pipeline} es separar los componentes de la imágen.
Las dos maneras más comunes de representar imágenes en computadoras es
\verb+RGB+ o \verb+RGBA+: En ambos formatos, cada píxel ocupa 32 bits de
espacio, divididos en componentes de 8 bits. Cada componente corresponde a un
color o al valor de opacidad, comúnmente denominado \emph{alpha}. \verb+RGB+
corresponde al byte \verb+RRGGBBXX+, con \verb+RR+ representando rojo,
\verb+GG+ representando verde y \verb+BB+ representando azul. Aunque a veces
decimos que \verb+RGB+ es un formato de 24 bits, especificamos el byte
\verb+XX+ por convención, ya que siempre se utilizan 32 bits (4 bytes) para
representar RGB. \verb+RGBA+ es análogo a \verb+RGB+. Le corresponden los 4
bytes \verb+RRGGBBAA+, donde el último byte se usa para el valor \emph{alpha}.

\subsection{Endianness}

Cabe notar que diferentes plataformas tienen diferentes convenciones para
guardar colores en memoria. Windows espera que le mandemos píxeles en órden
\verb+BGRA+, ya que al inspeccionar la memoria se ve en el órden más familiar
de \verb+ARGB+ (Microsoft no ha dicho públicamente por qué reordenaron los
componentes de color pero no el de opacidad).

Este tema toca el concepto de \emph{endianness}, que es el término que usamos
para referirnos al orden de los bytes en una palabra de memoria. En
procesadores modernos, una palabra son 32 bits. 4 bytes, cada uno de 8 bits. La
mayoría de las instrucciones que se ejecutan toman palabras como parámetros, y
cuando nos importan los detalles de bajo nivel entonces debemos de entender la
diferencia entre arquitecturas \emph{little endian} y \emph{big endian}. Una
arquitectura \emph{Little endian} guarda los bytes de una palabra de izquierda
a derecha del menos significativo al más significativo. Es más claro usar el
ejemplo concreto de los colores representados en palabras de 32 bits. Un color
\verb+RGBA+ consiste de 4 bytes y en una máquina little endian se guarda en la
memoria de la computadora como \verb+ABGR+. En una máquina \emph{big endian},
se guarda de la misma manera en que lo escribirmos: \verb+RGBA+. En ambos tipos
de ordenamiento de memoria, su \emph{endianness} afecta sólamente al
ordenamiento de bytes dentro de palábras de máquina. No hay que confundirnos y
pensar que el efecto se extiende más allá de una palabra de 32 bits. Si tenemos
dos palabras \verb+U = abcd+ y \verb+V = efgh+ entonces \verb+UV+ se ve en
memoria como \verb+dcbahgfe+. Los bytes se voltean dentro de las palabras
individuales, pero las palabras siempre van de izquierda a derecha.
Procesadores ARM después de la versión 3 son \emph{bi-endian}; pueden
seleccionar su \emph{endianness} desde software.

En ensamblador con sintaxis de Intel o en el API de Windows, se utiliza
\verb+BYTE+ para denotar 8 bits, \verb+WORD+ para 16 bits, \verb+DWORD+ para 32
bits y \verb+QWORD+ para 64 bits. Esta convención viene de cuando los
procesadores eran de 16 bits, y no cambió ni en la transición a 32 bits en los
90's ni en la transición a 64 bits en los 00's

El codificador JPEG que escribimos asume que la máquina en la que se está
corriendo es \emph{little endian}.


\subsection{La DCT}

La transformada discreta de coseno, \emph{DCT} por sus siglas en Inglés, puede
representar $N$ puntos como una suma con pesos de funciones cosenoidales de
diferentes frecuencias. Es popular en compresión porque las señales que
comprimimos tienden a tener una representación con bajas frecuencias
predominantes. Por ejemplo, es más común una imagen de un cielo azul que ruido
blanco en todos los colores. Una imagen de un cielo azul tiene muy poca
variación, que al aplicar \emph{DCT} resulta en un peso alto para frecuencias
bajas y pesos más cercanos a cero para frecuencias más altas.

En JPEG, se divide la imagen en bloques de $8\times8$ y se utiliza una \emph{DCT} de $8\times8$:
\begin{equation}\label{eq:dct}
F(u, v) = \frac{1}{4} C(u)C(v) \sum_{x=0}^{7}\sum_{y=0}^{7}
f(x,y)*\cos{\frac{(2x+1)u\pi}{16}}\cos{\frac{(2y+1)v\pi}{16}}
\end{equation}
donde \[C(u), C(v) = \begin{cases}
        \frac{1}{\sqrt{2}} & \quad \text{para } u,v = 0\\
        1                  & \quad \text{para } u,v \neq 0\\
\end{cases} \]
\begin{eqnarray*}
    f(u, v) \text{ es un punto del bloque de } 8\times8 \text{ de la imagen }\\
    F(u, v) \text{ es la DCT para el punto } u,v\\
\end{eqnarray*}

De la ecuación \ref{eq:dct} se puede derivar directamente un algoritmo para la
\emph{DCT}, visto más a detalle en el capítulo \ref{ch:implementacion}.



\subsection{La vida de un bloque}\label{sub:vida}



JPEG trabaja dividiendo a la imagen en bloques cuadrados de 8 píxeles de ancho y alto. Si el tamaño de la imagen no es un múltiplo de ocho, se redondea al siguiente número que sí lo es y es el trabajo del decodificador ignorar los píxeles sobrantes. Cada bloque es independiente de los demás y por lo tanto el algoritmo es altamente paralelizable. Es una buena coincidencia que las arquitecturas de GPU de hoy en día trabajan con grupos de 64 \emph{threads}.

Cada bloque pasa por varias etapas antes de ser escrito a memoria como bits comprimidos de JPEG.


\subsection{YUV}\label{sub:yuv}

Cada bloque crudo de la imágen se convierte en tres nuevos bloques, cada uno correspondiente a un componente del modelo de color \verb+YUV+, también denominado \verb+YCbCr+

Un modelo de color es una manera abstracta de representar colores. \verb+RGB+ representa colores como combinaciones de tres colores primarios. \verb+YUV+ los representa en tres componentes, uno para Luminancia y dos de Crominancia.

Luminancia, también llamado Luma o \verb+Y+, es la intensidad de la imagen. La Crominancia, también llamada Chroma describe el color de la imagen y se codifica con dos componentes \verb+U+ o \verb+Cb+ y \verb+V+ o \verb+Cr+, donde $U = Azul - Luminancia$ y $V = Rojo - Luminancia$.

El modelo de color \verb+YUV+ se inventó con la invención de la televisión a color. La luminancia no es otra cosa que la imagen en blanco y negro. La transición al color se hizo gradualmente transmitiendo la información de la misma manera que antes, pero usando dos nuevos canales, \verb+U+ y \verb+V+. De esta manera, el nuevo formato era compatible con televisiones en blanco y negro, que sólo necesitaban la información de uno de los canales.

\begin{figure}[hb]
\includegraphics{yuv_cable}
    \caption{La siguiente generación no va a saber para que eran estos cables}
\end{figure}

Los cables RCA empezaron transmitiendo los tres componentes de \verb+YUV+. Más tarde, cuando todos tenían color, se migró a usar un cable para \verb+YUV+, llamado "video compuesto" y los otros dos para sonido estéreo.

\begin{figure}
    \includegraphics{yuv}
    \caption{Descomposición de una imagen a un canal de Luma y dos de Chroma}
\end{figure}

\verb+YUV+ tiene ventajas para comprimir imágenes. El sistema de visión humano es mucho más sensible a cambios de intensidad en la imagen que a cambios de color. Esto se aprovechaba en los días de la televisión analógica para utilizar más ancho de banda en Luma que en Chroma, y el mismo principio se utiliza en JPEG, cuya especificación incluye la opción de usar resoluciones más bajas para los canales de chroma que el de luma. La implementación de \verb+tiny_jpeg+ usa la misma resolución para los tres canales.

Los tres bloques correspondientes a \verb+Y+, \verb+U+, y \verb+V+ son escritos al archivo en ese orden después de ser transformados independientemente.


\subsection{Aplicación de DCT y Cuantización}

\begin{figure}[hb]
    \includegraphics{DCT-8x8}
    \caption{Visualización de las funciones para el DCT de 8x8 usado en JPEG. Esquina superior izquierda: menor frecuencia. Inferior derecha: mayor frecuencia.}
    \label{fig:dct}
\end{figure}



Al bloque se le aplica la Transformada Discreta de Coseno de $8\times8$. El resultado son 64 coeficientes para las 64 funciones base. Como se muestra en la figura \ref{fig:dct}, la frecuencia se incrementa hacia la derecha y abajo. Por eso a partir de este momento se itera el bloque en un patrón de zig-zag \ref{fig:zigzag}. Empezando en la esquina superior izquierda y acabando en la inferior derecha.

\begin{figure}[h]
    \includegraphics{zigzag}
    \caption{El patrón zig-zag con el que se itera por los bloques.}
    \label{fig:zigzag}
\end{figure}

El corazón de JPEG es en el proceso de cuantización. Para cada codificador, usualmente elegido por heurísticas \emph{ a priori }, le corresponde al menos dos tablas de cuantización de 64 elementos. El propósito de estas tablas es decidir cuanta información queremos perder para diferentes frecuencias.




%%% Local Variables:
%%% mode: latex
%%% ispell-local-dictionary: "espanol"
%%% TeX-engine: xelatex
%%% TeX-master: "../tesis"
%
